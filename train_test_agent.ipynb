{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d759dd8-6fab-49cf-962c-13f852fe4fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2147483648"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "ctypes.windll.kernel32.SetThreadExecutionState(0x80000002)\n",
    "# ctypes.windll.kernel32.SetThreadExecutionState(0x80000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0451974-70fe-4ee7-8aa1-4a6ebd1fa58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories already exist. Skipping train-val-test split.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import grid2op\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from grid2op.Runner import Runner\n",
    "from agent_wrapper import Grid2opAgentWrapper\n",
    "# from env_wrapper import Grid2opEnvWrapper\n",
    "from env_wrapper_custom import Grid2opEnvWrapper\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from grid2op.Reward import EpisodeDurationReward, L2RPNReward\n",
    "\n",
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "base_path = os.path.expanduser(\"C:/Users/henri/data_grid2op\")\n",
    "train_dir = os.path.join(base_path, f\"{env_name}_train\")\n",
    "val_dir = os.path.join(base_path, f\"{env_name}_val\")\n",
    "test_dir = os.path.join(base_path, f\"{env_name}_test\")\n",
    "\n",
    "def directories_exist(train_path, val_path, test_path):\n",
    "    return os.path.exists(train_path) and os.path.exists(val_path) and os.path.exists(test_path)\n",
    "\n",
    "# Make environment\n",
    "env = grid2op.make(env_name, reward_class=EpisodeDurationReward)\n",
    "\n",
    "if directories_exist(train_dir, val_dir, test_dir):\n",
    "    print(\"Directories already exist. Skipping train-val-test split.\")\n",
    "else:\n",
    "    print(\"Directories do not exist. Proceeding with train-val-test split.\")\n",
    "    # Perform the split\n",
    "    try:\n",
    "        nm_env_train, nm_env_val, nm_env_test = env.train_val_split_random(\n",
    "            pct_val=10, # 10% validation\n",
    "            pct_test=10, # 10% test\n",
    "            add_for_train=\"train\",\n",
    "            add_for_val=\"val\",\n",
    "            add_for_test=\"test\"\n",
    "        )\n",
    "        print(f\"Training environment created: {nm_env_train}\")\n",
    "        print(f\"Validation environment created: {nm_env_val}\")\n",
    "        print(f\"Test environment created: {nm_env_test}\")\n",
    "    except OSError as e:\n",
    "        print(f\"An error occurred during splitting: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c244af3-6d15-4ae6-8d90-f9d174ef9d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8fbd67-696e-4572-89e0-9f0bedb177c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ./PPO_default_sandbox\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"./tensorboard_logs/\"\n",
    "\n",
    "tb_log_name = \"PPO_default_Grid2op\"\n",
    "model_path = \"./PPO_default_sandbox\"\n",
    "\n",
    "env_config = {\n",
    "    # \"backend_cls\": ,\n",
    "    # \"backend_options\": {},\n",
    "    \"env_name\": \"l2rpn_case14_sandbox\", # \"l2rpn_neurips_2020_track1_small\"\n",
    "    \"env_is_test\": False,\n",
    "    \"obs_attr_to_keep\": [\"gen_p\", \"p_or\" ,\"load_p\", \"rho\", \"line_status\"], # \"gen_q\", \"gen_v\",\n",
    "    \"act_type\": \"discrete\", # \"discrete\" \"box\" \"multi_discrete\"\n",
    "    \"act_attr_to_keep\": [\"change_line_status\", \"set_line_status_simple\", \"set_bus\"], # set_line_status\n",
    "    \"reward_class\": EpisodeDurationReward,\n",
    "    \"data_set\": \"train\", # for training data set train/val/test\n",
    "}\n",
    "\n",
    "\n",
    "vec_env = make_vec_env(lambda: Grid2opEnvWrapper(env_config), n_envs=1)\n",
    "\n",
    "#sb3_algo2 = PPO.load(model_path, env=vec_env)\n",
    "#print(\"Model loaded successfully\")\n",
    "\n",
    "\n",
    "custom_hyperparameters = {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.99,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"clip_range_vf\": None,\n",
    "    \"normalize_advantage\": True,\n",
    "    \"ent_coef\": 0.0,\n",
    "    \"vf_coef\": 0.5,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"use_sde\": False,\n",
    "    \"sde_sample_freq\": -1,\n",
    "    \"target_kl\": None,\n",
    "}\n",
    "\n",
    "# Initialize PPO with custom hyperparameters\n",
    "sb3_algo = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    verbose=0,\n",
    "    tensorboard_log=\"./tensorboard_logs/\",\n",
    "    **custom_hyperparameters\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "sb3_algo.learn(total_timesteps=1_000_000, tb_log_name=tb_log_name)\n",
    "\n",
    "# Save the model\n",
    "sb3_algo.save(model_path)\n",
    "\n",
    "print(f\"Model saved at {model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65912e31-be5a-4157-8be1-c660ef2f7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_wrapper import Grid2opAgentWrapper\n",
    "from grid2op.Runner import Runner\n",
    "\n",
    "nb_episode_test = 2\n",
    "seeds_test_env = (0, 1)    # same size as nb_episode_test\n",
    "seeds_test_agent = (3, 4)  # same size as nb_episode_test\n",
    "ts_ep_test =  (0, 1)       # same size as nb_episode_test\n",
    "\n",
    "# uncomment those two line if the env_config is the correct for the tested agent\n",
    "# test_env_config = env_config\n",
    "# test_env_config[\"data_set\"] = \"val\"\n",
    "\n",
    "\n",
    "test_env_config = {\n",
    "    # \"backend_cls\": ,\n",
    "    # \"backend_options\": {},\n",
    "    \"env_name\": \"l2rpn_case14_sandbox\", # \"l2rpn_neurips_2020_track1_small\"\n",
    "    \"env_is_test\": False,\n",
    "    # \"obs_attr_to_keep\": [\"gen_p\", \"p_or\" ,\"load_p\", \"rho\", \"line_status\"], # \"gen_q\", \"gen_v\",\n",
    "    \"act_type\": \"discrete\", # \"discrete\" \"box\" \"multi_discrete\"\n",
    "    # \"act_attr_to_keep\": [\"change_line_status\", \"set_line_status_simple\", \"set_bus\"], # set_line_status\n",
    "    \"reward_class\": EpisodeDurationReward,\n",
    "    \"data_set\": \"val\", # for training data set train/val/test\n",
    "}\n",
    "\n",
    "\n",
    "# test_vec_env = make_vec_env(lambda: Grid2opEnvWrapper(test_env_config), n_envs=1)\n",
    "\n",
    "test_env = Grid2opEnvWrapper(test_env_config)\n",
    "\n",
    "sb3_algo_to_test = PPO.load(model_path, env=test_env)\n",
    "\n",
    "my_agent = Grid2opAgentWrapper(test_env, sb3_algo_to_test)\n",
    "runner = Runner(**test_env._g2op_env.get_params_for_runner(),\n",
    "                agentClass=None,\n",
    "                agentInstance=my_agent)\n",
    "\n",
    "res = runner.run(nb_episode=nb_episode_test,\n",
    "                 env_seeds=seeds_test_env,\n",
    "                 agent_seeds=seeds_test_agent,\n",
    "                 episode_id=ts_ep_test,\n",
    "                 add_detailed_output=True,\n",
    "                 path_save=model_path+\"_val\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "791bef8d-55d2-41f7-91ea-2c38ef86ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1:\n",
      "  Chronics Name: C:\\Users\\henri\\data_grid2op\\l2rpn_case14_sandbox_val\\chronics\\0021\n",
      "  Cumulative Reward: 0021\n",
      "  Number of Time Steps: 0.13578869047619047\n",
      "  Maximum Time Steps: 1095\n",
      "  Detailed Data:\n",
      "    Time Step 0:\n",
      "      Observation: <grid2op.Space.GridObjects.CompleteObservation_l2rpn_case14_sandbox_val object at 0x00000246A7699390>\n",
      "      Action Taken: This action will:\n",
      "\t - NOT change anything to the injections\n",
      "\t - NOT perform any redispatching action\n",
      "\t - NOT modify any storage capacity\n",
      "\t - NOT perform any curtailment\n",
      "\t - NOT force any line status\n",
      "\t - NOT switch any line status\n",
      "\t - NOT switch anything in the topology\n",
      "\t - Set the bus of the following element(s):\n",
      "\t \t - Assign bus 1 to line (origin) id 7 [on substation 5]\n",
      "\t \t - Assign bus 1 to line (origin) id 8 [on substation 5]\n",
      "\t \t - Assign bus 1 to line (origin) id 9 [on substation 5]\n",
      "\t \t - Assign bus 1 to line (extremity) id 17 [on substation 5]\n",
      "\t \t - Assign bus 1 to generator id 2 [on substation 5]\n",
      "\t \t - Assign bus 1 to generator id 3 [on substation 5]\n",
      "\t \t - Assign bus 1 to load id 4 [on substation 5]\n",
      "      Reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "for ep_data in res:\n",
    "    chron_name, cum_reward, nb_time_step, max_ts, _, ep_data = ep_data\n",
    "    print(f\"Episode {i + 1}:\")\n",
    "    print(f\"  Chronics Name: {chron_name}\")\n",
    "    print(f\"  Cumulative Reward: {cum_reward}\")\n",
    "    print(f\"  Number of Time Steps: {nb_time_step}\")\n",
    "    print(f\"  Maximum Time Steps: {max_ts}\")\n",
    "    print(\"  Detailed Data:\")\n",
    "    for t, obs in enumerate(ep_data.observations):\n",
    "        print(f\"    Time Step {t}:\")\n",
    "        print(f\"      Observation: {obs}\")\n",
    "        print(f\"      Action Taken: {ep_data.actions[t]}\")\n",
    "        print(f\"      Reward: {ep_data.rewards[t]}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0403a30-4fd5-4851-9051-b39cb9a51fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a00344-fd54-43b8-8361-6b6f878321e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
